{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\mpich\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\mpich\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\mpich\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\mpich\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\mpich\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\mpich\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Ora</th>\n",
       "      <th>PUN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20170101</td>\n",
       "      <td>1</td>\n",
       "      <td>53.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20170101</td>\n",
       "      <td>2</td>\n",
       "      <td>52.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20170101</td>\n",
       "      <td>3</td>\n",
       "      <td>51.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20170101</td>\n",
       "      <td>4</td>\n",
       "      <td>47.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20170101</td>\n",
       "      <td>5</td>\n",
       "      <td>45.49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Data  Ora    PUN\n",
       "0  20170101    1  53.30\n",
       "1  20170101    2  52.00\n",
       "2  20170101    3  51.00\n",
       "3  20170101    4  47.27\n",
       "4  20170101    5  45.49"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"manipulated_pun.csv\", sep=\";\", decimal=',', header='infer')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Data\"] = df[\"Data\"].apply(lambda x: str(x))\n",
    "df[\"Data\"] = df[\"Data\"].apply(lambda x: datetime.datetime.strptime(x,\"%Y%m%d\"))\n",
    "df = df.loc[df['Data'] <= '2020-01-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Ora2\"] = pd.to_datetime(df.Ora, unit=\"h\").dt.strftime(\"%H:%M\")\n",
    "df[\"Datetime\"] = df[\"Data\"].dt.strftime(\"%Y-%m-%d\") + \" \" + df[\"Ora2\"]\n",
    "df.index = pd.DatetimeIndex(df.Datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Ora</th>\n",
       "      <th>PUN</th>\n",
       "      <th>Ora2</th>\n",
       "      <th>Datetime</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-01 01:00:00</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>53.30</td>\n",
       "      <td>01:00</td>\n",
       "      <td>2017-01-01 01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 02:00:00</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>2</td>\n",
       "      <td>52.00</td>\n",
       "      <td>02:00</td>\n",
       "      <td>2017-01-01 02:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 03:00:00</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>3</td>\n",
       "      <td>51.00</td>\n",
       "      <td>03:00</td>\n",
       "      <td>2017-01-01 03:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 04:00:00</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>4</td>\n",
       "      <td>47.27</td>\n",
       "      <td>04:00</td>\n",
       "      <td>2017-01-01 04:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 05:00:00</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>5</td>\n",
       "      <td>45.49</td>\n",
       "      <td>05:00</td>\n",
       "      <td>2017-01-01 05:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Data  Ora    PUN   Ora2          Datetime\n",
       "Datetime                                                           \n",
       "2017-01-01 01:00:00 2017-01-01    1  53.30  01:00  2017-01-01 01:00\n",
       "2017-01-01 02:00:00 2017-01-01    2  52.00  02:00  2017-01-01 02:00\n",
       "2017-01-01 03:00:00 2017-01-01    3  51.00  03:00  2017-01-01 03:00\n",
       "2017-01-01 04:00:00 2017-01-01    4  47.27  04:00  2017-01-01 04:00\n",
       "2017-01-01 05:00:00 2017-01-01    5  45.49  05:00  2017-01-01 05:00"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df[\"PUN\"]\n",
    "df[\"df24\"] = target.shift(24)\n",
    "target = df[\"PUN\"].iloc[25:]\n",
    "features = df[[\"PUN\", \"df24\"]].iloc[25:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Ora</th>\n",
       "      <th>PUN</th>\n",
       "      <th>Ora2</th>\n",
       "      <th>Datetime</th>\n",
       "      <th>df24</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-01 01:00:00</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>53.30</td>\n",
       "      <td>01:00</td>\n",
       "      <td>2017-01-01 01:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 02:00:00</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>2</td>\n",
       "      <td>52.00</td>\n",
       "      <td>02:00</td>\n",
       "      <td>2017-01-01 02:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 03:00:00</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>3</td>\n",
       "      <td>51.00</td>\n",
       "      <td>03:00</td>\n",
       "      <td>2017-01-01 03:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 04:00:00</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>4</td>\n",
       "      <td>47.27</td>\n",
       "      <td>04:00</td>\n",
       "      <td>2017-01-01 04:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 05:00:00</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>5</td>\n",
       "      <td>45.49</td>\n",
       "      <td>05:00</td>\n",
       "      <td>2017-01-01 05:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-24 20:00:00</th>\n",
       "      <td>2019-12-24</td>\n",
       "      <td>20</td>\n",
       "      <td>47.43</td>\n",
       "      <td>20:00</td>\n",
       "      <td>2019-12-24 20:00</td>\n",
       "      <td>44.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-24 21:00:00</th>\n",
       "      <td>2019-12-24</td>\n",
       "      <td>21</td>\n",
       "      <td>45.70</td>\n",
       "      <td>21:00</td>\n",
       "      <td>2019-12-24 21:00</td>\n",
       "      <td>40.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-24 22:00:00</th>\n",
       "      <td>2019-12-24</td>\n",
       "      <td>22</td>\n",
       "      <td>36.53</td>\n",
       "      <td>22:00</td>\n",
       "      <td>2019-12-24 22:00</td>\n",
       "      <td>36.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-24 23:00:00</th>\n",
       "      <td>2019-12-24</td>\n",
       "      <td>23</td>\n",
       "      <td>27.46</td>\n",
       "      <td>23:00</td>\n",
       "      <td>2019-12-24 23:00</td>\n",
       "      <td>31.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-24 00:00:00</th>\n",
       "      <td>2019-12-24</td>\n",
       "      <td>24</td>\n",
       "      <td>20.99</td>\n",
       "      <td>00:00</td>\n",
       "      <td>2019-12-24 00:00</td>\n",
       "      <td>18.58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26112 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Data  Ora    PUN   Ora2          Datetime   df24\n",
       "Datetime                                                                  \n",
       "2017-01-01 01:00:00 2017-01-01    1  53.30  01:00  2017-01-01 01:00    NaN\n",
       "2017-01-01 02:00:00 2017-01-01    2  52.00  02:00  2017-01-01 02:00    NaN\n",
       "2017-01-01 03:00:00 2017-01-01    3  51.00  03:00  2017-01-01 03:00    NaN\n",
       "2017-01-01 04:00:00 2017-01-01    4  47.27  04:00  2017-01-01 04:00    NaN\n",
       "2017-01-01 05:00:00 2017-01-01    5  45.49  05:00  2017-01-01 05:00    NaN\n",
       "...                        ...  ...    ...    ...               ...    ...\n",
       "2019-12-24 20:00:00 2019-12-24   20  47.43  20:00  2019-12-24 20:00  44.40\n",
       "2019-12-24 21:00:00 2019-12-24   21  45.70  21:00  2019-12-24 21:00  40.99\n",
       "2019-12-24 22:00:00 2019-12-24   22  36.53  22:00  2019-12-24 22:00  36.90\n",
       "2019-12-24 23:00:00 2019-12-24   23  27.46  23:00  2019-12-24 23:00  31.96\n",
       "2019-12-24 00:00:00 2019-12-24   24  20.99  00:00  2019-12-24 00:00  18.58\n",
       "\n",
       "[26112 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_test = df[\"Datetime\"] > \"2019-12-25\"\n",
    "mask_train = df[\"Datetime\"] <= \"2019-12-25\"\n",
    "\n",
    "# %%\n",
    "test = df.loc[mask_test]\n",
    "test\n",
    "\n",
    "# %%\n",
    "train = df.loc[mask_train]\n",
    "train\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = train['df24'][24:].values\n",
    "testX = test['df24'].values\n",
    "trainY = train['PUN'][24:].values\n",
    "testY = test[\"PUN\"].values\n",
    "\n",
    "trainY\n",
    "\n",
    "\n",
    "# %%\n",
    "testY.shape\n",
    "\n",
    "\n",
    "# %%\n",
    "trainX.shape = (26088, 1)\n",
    "testX.shape = (192, 1) \n",
    "trainY.shape = (26088, 1)\n",
    "testY.shape = (192, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data():\n",
    "    \n",
    "    df = pd.read_csv(\"manipulated_pun.csv\", sep=\";\", decimal=',', header='infer')\n",
    "    \n",
    "    df[\"Data\"] = df[\"Data\"].apply(lambda x: str(x))\n",
    "    df[\"Data\"] = df[\"Data\"].apply(lambda x: datetime.datetime.strptime(x,\"%Y%m%d\"))\n",
    "    df = df.loc[df['Data'] <= '2020-01-01']\n",
    "    \n",
    "    df[\"Ora2\"] = pd.to_datetime(df.Ora, unit=\"h\").dt.strftime(\"%H:%M\")\n",
    "    df[\"Datetime\"] = df[\"Data\"].dt.strftime(\"%Y-%m-%d\") + \" \" + df[\"Ora2\"]\n",
    "    df.index = pd.DatetimeIndex(df.Datetime)\n",
    "\n",
    "    target = df[\"PUN\"]\n",
    "    df[\"df24\"] = target.shift(24)\n",
    "    target = df[\"PUN\"].iloc[25:]\n",
    "    features = df[[\"PUN\", \"df24\"]].iloc[25:]\n",
    "    \n",
    "    mask_test = df[\"Datetime\"] > \"2019-12-25\"\n",
    "    mask_train = df[\"Datetime\"] <= \"2019-12-25\"\n",
    "\n",
    "    # %%\n",
    "    test = df.loc[mask_test]\n",
    "    test\n",
    "\n",
    "    # %%\n",
    "    train = df.loc[mask_train]\n",
    "    train\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    trainX = train['df24'][24:].values\n",
    "    testX = test['df24'].values\n",
    "    trainY = train['PUN'][24:].values\n",
    "    testY = test[\"PUN\"].values\n",
    "\n",
    "    trainY\n",
    "\n",
    "\n",
    "    # %%\n",
    "    testY.shape\n",
    "\n",
    "\n",
    "    # %%\n",
    "    trainX.shape = (26088, 1)\n",
    "    testX.shape = (192, 1) \n",
    "    trainY.shape = (26088, 1)\n",
    "    testY.shape = (192, 1)\n",
    "    \n",
    "    \n",
    "    scaler = MinMaxScaler(feature_range=(0,1))\n",
    "    X_train = scaler.fit_transform(trainX)\n",
    "    X_test = scaler.fit_transform(testX)\n",
    "    y_train = scaler.fit_transform(trainY)\n",
    "    y_test = scaler.fit_transform(testY)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(X_train, y_train, X_test, y_test):\n",
    "    import tensorflow.python.keras\n",
    "    from tensorflow.python.keras.models import Sequential\n",
    "    from tensorflow.python.keras.layers import Dense, Activation, Dropout\n",
    "    from tensorflow.python.keras import backend as K\n",
    "\n",
    "    from tensorflow.python.keras import utils, layers, Sequential\n",
    "    \n",
    "    model = Sequential()\n",
    "    # the model will take as input arrays of shape (*, X_train.shape[1])\n",
    "    # and output arrays of shape (*, 25)\n",
    "    model.add(Dense(64, input_shape=(X_train.shape[1],)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout({{uniform(0, 1)}}))\n",
    "    model.add(Dense({{choice([64, 128, 256, 512, 1024, 2048])}}))\n",
    "    model.add(Activation({{choice(['relu', 'sigmoid'])}}))\n",
    "    model.add(Dropout({{uniform(0, 1)}}))\n",
    "\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='mse', metrics=['mean_absolute_error'],\n",
    "                  optimizer={{choice(['rmsprop', 'adam', 'sgd'])}})\n",
    "\n",
    "    result = model.fit(X_train, y_train,\n",
    "              batch_size={{choice([22, 64, 128, 256, 512, 1024, 2048])}},\n",
    "              epochs=10,\n",
    "              verbose=2,\n",
    "              validation_split=0.15)\n",
    "    #get the highest validation mae of the training epochs\n",
    "    validation_mae = np.amax(result.history['mean_absolute_error']) \n",
    "    print('Best validation mae of epoch:', validation_mae)\n",
    "    return {'loss': validation_mae, 'status': STATUS_OK, 'model': model}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Imports:\n",
      "#coding=utf-8\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import os\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import datetime\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperopt import Trials, STATUS_OK, tpe\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas import optim\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas.distributions import choice, uniform\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.preprocessing import MinMaxScaler\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import tensorflow.python.keras\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from tensorflow.python.keras.models import Sequential\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from tensorflow.python.keras.layers import Dense, Activation, Dropout\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from tensorflow.python.keras import backend as K\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from tensorflow.python.keras import utils, layers, Sequential\n",
      "except:\n",
      "    pass\n",
      "\n",
      ">>> Hyperas search space:\n",
      "\n",
      "def get_space():\n",
      "    return {\n",
      "        'Dropout': hp.uniform('Dropout', 0, 1),\n",
      "        'Dense': hp.choice('Dense', [64, 128, 256, 512, 1024, 2048]),\n",
      "        'Activation': hp.choice('Activation', ['relu', 'sigmoid']),\n",
      "        'Dropout_1': hp.uniform('Dropout_1', 0, 1),\n",
      "        'optimizer': hp.choice('optimizer', ['rmsprop', 'adam', 'sgd']),\n",
      "        'batch_size': hp.choice('batch_size', [22, 64, 128, 256, 512, 1024, 2048]),\n",
      "    }\n",
      "\n",
      ">>> Data\n",
      "   1: \n",
      "   2: \n",
      "   3: df = pd.read_csv(\"manipulated_pun.csv\", sep=\";\", decimal=',', header='infer')\n",
      "   4: \n",
      "   5: df[\"Data\"] = df[\"Data\"].apply(lambda x: str(x))\n",
      "   6: df[\"Data\"] = df[\"Data\"].apply(lambda x: datetime.datetime.strptime(x,\"%Y%m%d\"))\n",
      "   7: df = df.loc[df['Data'] <= '2020-01-01']\n",
      "   8: \n",
      "   9: df[\"Ora2\"] = pd.to_datetime(df.Ora, unit=\"h\").dt.strftime(\"%H:%M\")\n",
      "  10: df[\"Datetime\"] = df[\"Data\"].dt.strftime(\"%Y-%m-%d\") + \" \" + df[\"Ora2\"]\n",
      "  11: df.index = pd.DatetimeIndex(df.Datetime)\n",
      "  12: \n",
      "  13: target = df[\"PUN\"]\n",
      "  14: df[\"df24\"] = target.shift(24)\n",
      "  15: target = df[\"PUN\"].iloc[25:]\n",
      "  16: features = df[[\"PUN\", \"df24\"]].iloc[25:]\n",
      "  17: \n",
      "  18: mask_test = df[\"Datetime\"] > \"2019-12-25\"\n",
      "  19: mask_train = df[\"Datetime\"] <= \"2019-12-25\"\n",
      "  20: \n",
      "  21: # %%\n",
      "  22: test = df.loc[mask_test]\n",
      "  23: test\n",
      "  24: \n",
      "  25: # %%\n",
      "  26: train = df.loc[mask_train]\n",
      "  27: train\n",
      "  28: \n",
      "  29: \n",
      "  30: \n",
      "  31: \n",
      "  32: trainX = train['df24'][24:].values\n",
      "  33: testX = test['df24'].values\n",
      "  34: trainY = train['PUN'][24:].values\n",
      "  35: testY = test[\"PUN\"].values\n",
      "  36: \n",
      "  37: trainY\n",
      "  38: \n",
      "  39: \n",
      "  40: # %%\n",
      "  41: testY.shape\n",
      "  42: \n",
      "  43: \n",
      "  44: # %%\n",
      "  45: trainX.shape = (26088, 1)\n",
      "  46: testX.shape = (192, 1) \n",
      "  47: trainY.shape = (26088, 1)\n",
      "  48: testY.shape = (192, 1)\n",
      "  49: \n",
      "  50: \n",
      "  51: scaler = MinMaxScaler(feature_range=(0,1))\n",
      "  52: X_train = scaler.fit_transform(trainX)\n",
      "  53: X_test = scaler.fit_transform(testX)\n",
      "  54: y_train = scaler.fit_transform(trainY)\n",
      "  55: y_test = scaler.fit_transform(testY)\n",
      "  56: \n",
      "  57: \n",
      "  58: \n",
      "  59: \n",
      ">>> Resulting replaced keras model:\n",
      "\n",
      "   1: def keras_fmin_fnct(space):\n",
      "   2: \n",
      "   3: \n",
      "   4:     \n",
      "   5:     model = Sequential()\n",
      "   6:     # the model will take as input arrays of shape (*, X_train.shape[1])\n",
      "   7:     # and output arrays of shape (*, 25)\n",
      "   8:     model.add(Dense(64, input_shape=(X_train.shape[1],)))\n",
      "   9:     model.add(Activation('relu'))\n",
      "  10:     model.add(Dropout(space['Dropout']))\n",
      "  11:     model.add(Dense(space['Dense']))\n",
      "  12:     model.add(Activation(space['Activation']))\n",
      "  13:     model.add(Dropout(space['Dropout_1']))\n",
      "  14: \n",
      "  15:     model.add(Dense(1))\n",
      "  16:     model.add(Activation('softmax'))\n",
      "  17: \n",
      "  18:     model.compile(loss='mse', metrics=['mean_absolute_error'],\n",
      "  19:                   optimizer=space['optimizer'])\n",
      "  20: \n",
      "  21:     result = model.fit(X_train, y_train,\n",
      "  22:               batch_size=space['batch_size'],\n",
      "  23:               epochs=10,\n",
      "  24:               verbose=2,\n",
      "  25:               validation_split=0.15)\n",
      "  26:     #get the highest validation mae of the training epochs\n",
      "  27:     validation_mae = np.amax(result.history['mean_absolute_error']) \n",
      "  28:     print('Best validation mae of epoch:', validation_mae)\n",
      "  29:     return {'loss': validation_mae, 'status': STATUS_OK, 'model': model}\n",
      "  30: \n",
      "  0%|          | 0/5 [00:00<?, ?trial/s, best loss=?]WARNING:tensorflow:From C:\\Users\\mpich\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\mpich\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\mpich\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 22174 samples, validate on 3914 samples     \n",
      "  0%|          | 0/5 [00:00<?, ?trial/s, best loss=?]WARNING:tensorflow:From C:\\Users\\mpich\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10                                           \n",
      " - 2s - loss: 0.4547 - mean_absolute_error: 0.6681 - val_loss: 0.5108 - val_mean_absolute_error: 0.7112\n",
      "\n",
      "Epoch 2/10                                           \n",
      " - 2s - loss: 0.4547 - mean_absolute_error: 0.6681 - val_loss: 0.5108 - val_mean_absolute_error: 0.7112\n",
      "\n",
      "Epoch 3/10                                           \n",
      " - 1s - loss: 0.4547 - mean_absolute_error: 0.6681 - val_loss: 0.5108 - val_mean_absolute_error: 0.7112\n",
      "\n",
      "Epoch 4/10                                           \n",
      " - 1s - loss: 0.4547 - mean_absolute_error: 0.6681 - val_loss: 0.5108 - val_mean_absolute_error: 0.7112\n",
      "\n",
      "Epoch 5/10                                           \n",
      " - 1s - loss: 0.4547 - mean_absolute_error: 0.6681 - val_loss: 0.5108 - val_mean_absolute_error: 0.7112\n",
      "\n",
      "Epoch 6/10                                           \n",
      " - 1s - loss: 0.4547 - mean_absolute_error: 0.6681 - val_loss: 0.5108 - val_mean_absolute_error: 0.7112\n",
      "\n",
      "Epoch 7/10                                           \n",
      " - 1s - loss: 0.4547 - mean_absolute_error: 0.6681 - val_loss: 0.5108 - val_mean_absolute_error: 0.7112\n",
      "\n",
      "Epoch 8/10                                           \n",
      " - 2s - loss: 0.4547 - mean_absolute_error: 0.6681 - val_loss: 0.5108 - val_mean_absolute_error: 0.7112\n",
      "\n",
      "Epoch 9/10                                           \n",
      " - 2s - loss: 0.4547 - mean_absolute_error: 0.6681 - val_loss: 0.5108 - val_mean_absolute_error: 0.7112\n",
      "\n",
      "Epoch 10/10                                          \n",
      " - 1s - loss: 0.4547 - mean_absolute_error: 0.6681 - val_loss: 0.5108 - val_mean_absolute_error: 0.7112\n",
      "\n",
      "Best validation mae of epoch:                        \n",
      "0.6681115                                            \n",
      "Train on 22174 samples, validate on 3914 samples                               \n",
      "Epoch 1/10                                                                     \n",
      " - 0s - loss: 0.4547 - mean_absolute_error: 0.6681 - val_loss: 0.5108 - val_mean_absolute_error: 0.7112\n",
      "\n",
      "Epoch 2/10                                                                     \n",
      " - 0s - loss: 0.4547 - mean_absolute_error: 0.6681 - val_loss: 0.5108 - val_mean_absolute_error: 0.7112\n",
      "\n",
      "Epoch 3/10                                                                     \n",
      " - 0s - loss: 0.4547 - mean_absolute_error: 0.6681 - val_loss: 0.5108 - val_mean_absolute_error: 0.7112\n",
      "\n",
      "Epoch 4/10                                                                     \n",
      " - 0s - loss: 0.4547 - mean_absolute_error: 0.6681 - val_loss: 0.5108 - val_mean_absolute_error: 0.7112\n",
      "\n",
      "Epoch 5/10                                                                     \n",
      " - 0s - loss: 0.4547 - mean_absolute_error: 0.6681 - val_loss: 0.5108 - val_mean_absolute_error: 0.7112\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10                                                                     \n",
      " - 0s - loss: 0.4547 - mean_absolute_error: 0.6681 - val_loss: 0.5108 - val_mean_absolute_error: 0.7112\n",
      "\n",
      "Epoch 7/10                                                                     \n",
      " - 0s - loss: 0.4547 - mean_absolute_error: 0.6681 - val_loss: 0.5108 - val_mean_absolute_error: 0.7112\n",
      "\n",
      "Epoch 8/10                                                                     \n",
      " - 0s - loss: 0.4547 - mean_absolute_error: 0.6681 - val_loss: 0.5108 - val_mean_absolute_error: 0.7112\n",
      "\n",
      "Epoch 9/10                                                                     \n",
      " - 0s - loss: 0.4547 - mean_absolute_error: 0.6681 - val_loss: 0.5108 - val_mean_absolute_error: 0.7112\n",
      "\n",
      "Epoch 10/10                                                                    \n",
      " - 0s - loss: 0.4547 - mean_absolute_error: 0.6681 - val_loss: 0.5108 - val_mean_absolute_error: 0.7112\n",
      "\n",
      "Best validation mae of epoch:                                                  \n",
      "0.6681114                                                                      \n",
      "Train on 22174 samples, validate on 3914 samples                               \n",
      "Epoch 1/10                                                                     \n",
      " - 1s - loss: 0.4547 - mean_absolute_error: 0.6681 - val_loss: 0.5108 - val_mean_absolute_error: 0.7112\n",
      "\n",
      "Epoch 2/10                                                                     \n",
      " - 0s - loss: 0.4547 - mean_absolute_error: 0.6681 - val_loss: 0.5108 - val_mean_absolute_error: 0.7112\n",
      "\n",
      "Epoch 3/10                                                                     \n",
      " - 0s - loss: 0.4547 - mean_absolute_error: 0.6681 - val_loss: 0.5108 - val_mean_absolute_error: 0.7112\n",
      "\n",
      "Epoch 4/10                                                                     \n",
      " - 1s - loss: 0.4547 - mean_absolute_error: 0.6681 - val_loss: 0.5108 - val_mean_absolute_error: 0.7112\n",
      "\n",
      "Epoch 5/10                                                                     \n",
      " - 1s - loss: 0.4547 - mean_absolute_error: 0.6681 - val_loss: 0.5108 - val_mean_absolute_error: 0.7112\n",
      "\n",
      "Epoch 6/10                                                                     \n",
      " - 1s - loss: 0.4547 - mean_absolute_error: 0.6681 - val_loss: 0.5108 - val_mean_absolute_error: 0.7112\n",
      "\n",
      "Epoch 7/10                                                                     \n",
      " - 1s - loss: 0.4547 - mean_absolute_error: 0.6681 - val_loss: 0.5108 - val_mean_absolute_error: 0.7112\n",
      "\n",
      "Epoch 8/10                                                                     \n",
      " - 1s - loss: 0.4547 - mean_absolute_error: 0.6681 - val_loss: 0.5108 - val_mean_absolute_error: 0.7112\n",
      "\n",
      "Epoch 9/10                                                                     \n",
      " - 1s - loss: 0.4547 - mean_absolute_error: 0.6681 - val_loss: 0.5108 - val_mean_absolute_error: 0.7112\n",
      "\n",
      "Epoch 10/10                                                                    \n",
      " - 1s - loss: 0.4547 - mean_absolute_error: 0.6681 - val_loss: 0.5108 - val_mean_absolute_error: 0.7112\n",
      "\n",
      "Best validation mae of epoch:                                                  \n",
      "0.66811144                                                                     \n",
      "Train on 22174 samples, validate on 3914 samples                               \n",
      "Epoch 1/10                                                                     \n",
      " - 1s - loss: 0.4547 - mean_absolute_error: 0.6681 - val_loss: 0.5108 - val_mean_absolute_error: 0.7112\n",
      "\n",
      "Epoch 2/10                                                                     \n",
      " - 1s - loss: 0.4547 - mean_absolute_error: 0.6681 - val_loss: 0.5108 - val_mean_absolute_error: 0.7112\n",
      "\n",
      "Epoch 3/10                                                                     \n",
      " - 1s - loss: 0.4547 - mean_absolute_error: 0.6681 - val_loss: 0.5108 - val_mean_absolute_error: 0.7112\n",
      "\n",
      "Epoch 4/10                                                                     \n",
      " - 1s - loss: 0.4547 - mean_absolute_error: 0.6681 - val_loss: 0.5108 - val_mean_absolute_error: 0.7112\n",
      "\n",
      "Epoch 5/10                                                                     \n",
      " - 1s - loss: 0.4547 - mean_absolute_error: 0.6681 - val_loss: 0.5108 - val_mean_absolute_error: 0.7112\n",
      "\n",
      "Epoch 6/10                                                                     \n",
      " - 1s - loss: 0.4547 - mean_absolute_error: 0.6681 - val_loss: 0.5108 - val_mean_absolute_error: 0.7112\n",
      "\n",
      "Epoch 7/10                                                                     \n",
      " - 1s - loss: 0.4547 - mean_absolute_error: 0.6681 - val_loss: 0.5108 - val_mean_absolute_error: 0.7112\n",
      "\n",
      "Epoch 8/10                                                                     \n",
      " - 1s - loss: 0.4547 - mean_absolute_error: 0.6681 - val_loss: 0.5108 - val_mean_absolute_error: 0.7112\n",
      "\n",
      "Epoch 9/10                                                                     \n",
      " - 1s - loss: 0.4547 - mean_absolute_error: 0.6681 - val_loss: 0.5108 - val_mean_absolute_error: 0.7112\n",
      "\n",
      "Epoch 10/10                                                                    \n",
      " - 1s - loss: 0.4547 - mean_absolute_error: 0.6681 - val_loss: 0.5108 - val_mean_absolute_error: 0.7112\n",
      "\n",
      "Best validation mae of epoch:                                                  \n",
      "0.66811144                                                                     \n",
      "Train on 22174 samples, validate on 3914 samples                               \n",
      "Epoch 1/10                                                                     \n",
      " - 2s - loss: 0.4547 - mean_absolute_error: 0.6681 - val_loss: 0.5108 - val_mean_absolute_error: 0.7112\n",
      "\n",
      "Epoch 2/10                                                                     \n",
      " - 1s - loss: 0.4547 - mean_absolute_error: 0.6681 - val_loss: 0.5108 - val_mean_absolute_error: 0.7112\n",
      "\n",
      "Epoch 3/10                                                                     \n",
      " - 1s - loss: 0.4547 - mean_absolute_error: 0.6681 - val_loss: 0.5108 - val_mean_absolute_error: 0.7112\n",
      "\n",
      "Epoch 4/10                                                                     \n",
      " - 1s - loss: 0.4547 - mean_absolute_error: 0.6681 - val_loss: 0.5108 - val_mean_absolute_error: 0.7112\n",
      "\n",
      "Epoch 5/10                                                                     \n",
      " - 1s - loss: 0.4547 - mean_absolute_error: 0.6681 - val_loss: 0.5108 - val_mean_absolute_error: 0.7112\n",
      "\n",
      "Epoch 6/10                                                                     \n",
      " - 1s - loss: 0.4547 - mean_absolute_error: 0.6681 - val_loss: 0.5108 - val_mean_absolute_error: 0.7112\n",
      "\n",
      "Epoch 7/10                                                                     \n",
      " - 1s - loss: 0.4547 - mean_absolute_error: 0.6681 - val_loss: 0.5108 - val_mean_absolute_error: 0.7112\n",
      "\n",
      "Epoch 8/10                                                                     \n",
      " - 1s - loss: 0.4547 - mean_absolute_error: 0.6681 - val_loss: 0.5108 - val_mean_absolute_error: 0.7112\n",
      "\n",
      "Epoch 9/10                                                                     \n",
      " - 1s - loss: 0.4547 - mean_absolute_error: 0.6681 - val_loss: 0.5108 - val_mean_absolute_error: 0.7112\n",
      "\n",
      "Epoch 10/10                                                                    \n",
      " - 1s - loss: 0.4547 - mean_absolute_error: 0.6681 - val_loss: 0.5108 - val_mean_absolute_error: 0.7112\n",
      "\n",
      "Best validation mae of epoch:                                                  \n",
      "0.6681115                                                                      \n",
      "100%|██████████| 5/5 [00:47<00:00,  9.49s/trial, best loss: 0.6681113839149475]\n"
     ]
    }
   ],
   "source": [
    "best_run, best_model = optim.minimize(model=create_model,\n",
    "                                      data=data,\n",
    "                                      algo=tpe.suggest,\n",
    "                                      max_evals=5,\n",
    "                                      trials=Trials(),\n",
    "                                      notebook_name='Hyperparameters_opt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best performing model chosen hyper-parameters:\n",
      "{'Activation': 0, 'Dense': 2, 'Dropout': 0.8366666847115819, 'Dropout_1': 0.9128294469805703, 'batch_size': 6, 'optimizer': 0}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best performing model chosen hyper-parameters:\")\n",
    "print(best_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python37364bitbaseconda44edad810ccb401d8f06f6ce310604dc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
