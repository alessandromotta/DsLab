{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Ora</th>\n",
       "      <th>PUN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20170101</td>\n",
       "      <td>1</td>\n",
       "      <td>53.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20170101</td>\n",
       "      <td>2</td>\n",
       "      <td>52.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20170101</td>\n",
       "      <td>3</td>\n",
       "      <td>51.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20170101</td>\n",
       "      <td>4</td>\n",
       "      <td>47.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20170101</td>\n",
       "      <td>5</td>\n",
       "      <td>45.49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Data  Ora    PUN\n",
       "0  20170101    1  53.30\n",
       "1  20170101    2  52.00\n",
       "2  20170101    3  51.00\n",
       "3  20170101    4  47.27\n",
       "4  20170101    5  45.49"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"manipulated_pun.csv\", sep=\";\", decimal=',', header='infer')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[['PUN']].values.astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = MinMaxScaler()\n",
    "\n",
    "# Create an object to transform the data to fit minmax processor\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "\n",
    "df_normalized = pd.DataFrame(x_scaled)\n",
    "\n",
    "df['PUN_n'] = df_normalized.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Data\"] = df[\"Data\"].apply(lambda x: str(x))\n",
    "df[\"Data\"] = df[\"Data\"].apply(lambda x: datetime.datetime.strptime(x,\"%Y%m%d\"))\n",
    "df = df.loc[df['Data'] < '2020-01-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Ora2\"] = pd.to_datetime(df.Ora, unit=\"h\").dt.strftime(\"%H:%M\")\n",
    "df[\"Datetime\"] = df[\"Data\"].dt.strftime(\"%Y-%m-%d\") + \" \" + df[\"Ora2\"]\n",
    "df.index = pd.DatetimeIndex(df.Datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Ora</th>\n",
       "      <th>PUN</th>\n",
       "      <th>PUN_n</th>\n",
       "      <th>Ora2</th>\n",
       "      <th>Datetime</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-01 01:00:00</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>53.30</td>\n",
       "      <td>0.313529</td>\n",
       "      <td>01:00</td>\n",
       "      <td>2017-01-01 01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 02:00:00</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>2</td>\n",
       "      <td>52.00</td>\n",
       "      <td>0.305882</td>\n",
       "      <td>02:00</td>\n",
       "      <td>2017-01-01 02:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 03:00:00</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>3</td>\n",
       "      <td>51.00</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>03:00</td>\n",
       "      <td>2017-01-01 03:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 04:00:00</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>4</td>\n",
       "      <td>47.27</td>\n",
       "      <td>0.278059</td>\n",
       "      <td>04:00</td>\n",
       "      <td>2017-01-01 04:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 05:00:00</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>5</td>\n",
       "      <td>45.49</td>\n",
       "      <td>0.267588</td>\n",
       "      <td>05:00</td>\n",
       "      <td>2017-01-01 05:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Data  Ora    PUN     PUN_n   Ora2          Datetime\n",
       "Datetime                                                                     \n",
       "2017-01-01 01:00:00 2017-01-01    1  53.30  0.313529  01:00  2017-01-01 01:00\n",
       "2017-01-01 02:00:00 2017-01-01    2  52.00  0.305882  02:00  2017-01-01 02:00\n",
       "2017-01-01 03:00:00 2017-01-01    3  51.00  0.300000  03:00  2017-01-01 03:00\n",
       "2017-01-01 04:00:00 2017-01-01    4  47.27  0.278059  04:00  2017-01-01 04:00\n",
       "2017-01-01 05:00:00 2017-01-01    5  45.49  0.267588  05:00  2017-01-01 05:00"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ora</th>\n",
       "      <th>PUN_n</th>\n",
       "      <th>df24</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-08 02:00:00</th>\n",
       "      <td>2</td>\n",
       "      <td>0.304824</td>\n",
       "      <td>0.305882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-08 03:00:00</th>\n",
       "      <td>3</td>\n",
       "      <td>0.301471</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-08 04:00:00</th>\n",
       "      <td>4</td>\n",
       "      <td>0.293941</td>\n",
       "      <td>0.278059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-08 05:00:00</th>\n",
       "      <td>5</td>\n",
       "      <td>0.282294</td>\n",
       "      <td>0.267588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-08 06:00:00</th>\n",
       "      <td>6</td>\n",
       "      <td>0.282353</td>\n",
       "      <td>0.268765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 20:00:00</th>\n",
       "      <td>20</td>\n",
       "      <td>0.332235</td>\n",
       "      <td>0.279000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 21:00:00</th>\n",
       "      <td>21</td>\n",
       "      <td>0.313176</td>\n",
       "      <td>0.268824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 22:00:00</th>\n",
       "      <td>22</td>\n",
       "      <td>0.298118</td>\n",
       "      <td>0.214882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 23:00:00</th>\n",
       "      <td>23</td>\n",
       "      <td>0.285941</td>\n",
       "      <td>0.161529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 00:00:00</th>\n",
       "      <td>24</td>\n",
       "      <td>0.248824</td>\n",
       "      <td>0.123471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26111 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Ora     PUN_n      df24\n",
       "Datetime                                    \n",
       "2017-01-08 02:00:00    2  0.304824  0.305882\n",
       "2017-01-08 03:00:00    3  0.301471  0.300000\n",
       "2017-01-08 04:00:00    4  0.293941  0.278059\n",
       "2017-01-08 05:00:00    5  0.282294  0.267588\n",
       "2017-01-08 06:00:00    6  0.282353  0.268765\n",
       "...                  ...       ...       ...\n",
       "2019-12-31 20:00:00   20  0.332235  0.279000\n",
       "2019-12-31 21:00:00   21  0.313176  0.268824\n",
       "2019-12-31 22:00:00   22  0.298118  0.214882\n",
       "2019-12-31 23:00:00   23  0.285941  0.161529\n",
       "2019-12-31 00:00:00   24  0.248824  0.123471\n",
       "\n",
       "[26111 rows x 3 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = df[\"PUN_n\"]\n",
    "df[\"df24\"] = target.shift(168)\n",
    "target = df[\"PUN_n\"].iloc[169:]\n",
    "features = df[[\"Ora\",\"PUN_n\", \"df24\"]].iloc[169:]\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.to_csv(r'file2.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ora</th>\n",
       "      <th>PUN_n</th>\n",
       "      <th>df24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.304824</td>\n",
       "      <td>0.305882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.301471</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.293941</td>\n",
       "      <td>0.278059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0.282294</td>\n",
       "      <td>0.267588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0.282353</td>\n",
       "      <td>0.268765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26106</th>\n",
       "      <td>20</td>\n",
       "      <td>0.332235</td>\n",
       "      <td>0.279000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26107</th>\n",
       "      <td>21</td>\n",
       "      <td>0.313176</td>\n",
       "      <td>0.268824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26108</th>\n",
       "      <td>22</td>\n",
       "      <td>0.298118</td>\n",
       "      <td>0.214882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26109</th>\n",
       "      <td>23</td>\n",
       "      <td>0.285941</td>\n",
       "      <td>0.161529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26110</th>\n",
       "      <td>24</td>\n",
       "      <td>0.248824</td>\n",
       "      <td>0.123471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26111 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Ora     PUN_n      df24\n",
       "0        2  0.304824  0.305882\n",
       "1        3  0.301471  0.300000\n",
       "2        4  0.293941  0.278059\n",
       "3        5  0.282294  0.267588\n",
       "4        6  0.282353  0.268765\n",
       "...    ...       ...       ...\n",
       "26106   20  0.332235  0.279000\n",
       "26107   21  0.313176  0.268824\n",
       "26108   22  0.298118  0.214882\n",
       "26109   23  0.285941  0.161529\n",
       "26110   24  0.248824  0.123471\n",
       "\n",
       "[26111 rows x 3 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"file2.csv\", sep=\",\", decimal='.', header='infer')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data():\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    df = pd.read_csv(\"file2.csv\", sep=\",\", decimal='.', header='infer')\n",
    "    train, test = train_test_split(df, test_size=0.2)\n",
    "    df = df.drop(['df24'], axis =1)\n",
    "    X_train = train[[\"df24\"]][168:]\n",
    "    X_test = test[[\"df24\"]]\n",
    "    y_train = train[[\"PUN_n\"]][168:]\n",
    "    y_test = test[[\"PUN_n\"]]\n",
    "    X_train = X_train.values\n",
    "    X_test = X_test.values\n",
    "    return X_train, y_train, X_test, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(X_train, y_train, X_test, y_test):\n",
    "    import tensorflow.python.keras\n",
    "    from tensorflow.python.keras.models import Sequential\n",
    "    from tensorflow.python.keras.layers import Dense, Activation, Dropout\n",
    "    from tensorflow.python.keras import backend as K\n",
    "\n",
    "    from tensorflow.python.keras import utils, layers, Sequential\n",
    "    \n",
    "    model = Sequential()\n",
    "    # the model will take as input arrays of shape (*, X_train.shape[1])\n",
    "    # and output arrays of shape (*, 25)\n",
    "    model.add(Dense(25, input_shape=(X_train.shape[1],)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout({{uniform(0, 1)}}))\n",
    "    model.add(Dense({{choice([64, 128, 256, 512, 1024])}}))\n",
    "    model.add(Activation({{choice(['relu', 'sigmoid'])}}))\n",
    "    model.add(Dropout({{uniform(0, 1)}}))\n",
    "\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='mse', metrics=['mean_absolute_error'],\n",
    "                  optimizer={{choice(['rmsprop', 'adam', 'sgd'])}})\n",
    "\n",
    "    result = model.fit(X_train, y_train,\n",
    "              batch_size={{choice([22, 64, 128, 256, 512, 1024])}},\n",
    "              epochs=1000,\n",
    "              verbose=2,\n",
    "              validation_split=0.1)\n",
    "    #get the highest validation mae of the training epochs\n",
    "    validation_mae = np.amax(result.history['mean_absolute_error']) \n",
    "    print('Best validation mae of epoch:', validation_mae)\n",
    "    return {'loss': validation_mae, 'status': STATUS_OK, 'model': model}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Imports:\n",
      "#coding=utf-8\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import os\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import datetime\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperopt import Trials, STATUS_OK, tpe\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas import optim\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas.distributions import choice, uniform\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.preprocessing import MinMaxScaler\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.model_selection import train_test_split\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import tensorflow.python.keras\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from tensorflow.python.keras.models import Sequential\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from tensorflow.python.keras.layers import Dense, Activation, Dropout\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from tensorflow.python.keras import backend as K\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from tensorflow.python.keras import utils, layers, Sequential\n",
      "except:\n",
      "    pass\n",
      "\n",
      ">>> Hyperas search space:\n",
      "\n",
      "def get_space():\n",
      "    return {\n",
      "        'Dropout': hp.uniform('Dropout', 0, 1),\n",
      "        'Dense': hp.choice('Dense', [64, 128, 256, 512, 1024]),\n",
      "        'Activation': hp.choice('Activation', ['relu', 'sigmoid']),\n",
      "        'Dropout_1': hp.uniform('Dropout_1', 0, 1),\n",
      "        'optimizer': hp.choice('optimizer', ['rmsprop', 'adam', 'sgd']),\n",
      "        'batch_size': hp.choice('batch_size', [22, 64, 128, 256, 512, 1024]),\n",
      "    }\n",
      "\n",
      ">>> Data\n",
      "  1: \n",
      "  2: from sklearn.model_selection import train_test_split\n",
      "  3: df = pd.read_csv(\"file2.csv\", sep=\",\", decimal='.', header='infer')\n",
      "  4: train, test = train_test_split(df, test_size=0.2)\n",
      "  5: df = df.drop(['df24'], axis =1)\n",
      "  6: X_train = train[[\"df24\"]][168:]\n",
      "  7: X_test = test[[\"df24\"]]\n",
      "  8: y_train = train[[\"PUN_n\"]][168:]\n",
      "  9: y_test = test[[\"PUN_n\"]]\n",
      " 10: X_train = X_train.values\n",
      " 11: X_test = X_test.values\n",
      " 12: \n",
      " 13: \n",
      " 14: \n",
      ">>> Resulting replaced keras model:\n",
      "\n",
      "   1: def keras_fmin_fnct(space):\n",
      "   2: \n",
      "   3: \n",
      "   4:     \n",
      "   5:     model = Sequential()\n",
      "   6:     # the model will take as input arrays of shape (*, X_train.shape[1])\n",
      "   7:     # and output arrays of shape (*, 25)\n",
      "   8:     model.add(Dense(25, input_shape=(X_train.shape[1],)))\n",
      "   9:     model.add(Activation('relu'))\n",
      "  10:     model.add(Dropout(space['Dropout']))\n",
      "  11:     model.add(Dense(space['Dense']))\n",
      "  12:     model.add(Activation(space['Activation']))\n",
      "  13:     model.add(Dropout(space['Dropout_1']))\n",
      "  14: \n",
      "  15:     model.add(Dense(1))\n",
      "  16:     model.add(Activation('softmax'))\n",
      "  17: \n",
      "  18:     model.compile(loss='mse', metrics=['mean_absolute_error'],\n",
      "  19:                   optimizer=space['optimizer'])\n",
      "  20: \n",
      "  21:     result = model.fit(X_train, y_train,\n",
      "  22:               batch_size=space['batch_size'],\n",
      "  23:               epochs=1000,\n",
      "  24:               verbose=2,\n",
      "  25:               validation_split=0.1)\n",
      "  26:     #get the highest validation mae of the training epochs\n",
      "  27:     validation_mae = np.amax(result.history['mean_absolute_error']) \n",
      "  28:     print('Best validation mae of epoch:', validation_mae)\n",
      "  29:     return {'loss': validation_mae, 'status': STATUS_OK, 'model': model}\n",
      "  30: \n",
      "Train on 18648 samples, validate on 2072 samples     \n",
      "Epoch 1/1000                                         \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 2/1000                                         \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 3/1000                                         \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 4/1000                                         \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 5/1000                                         \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 6/1000                                         \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 7/1000                                         \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 8/1000                                         \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 9/1000                                         \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 10/1000                                        \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 11/1000                                        \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 12/1000                                        \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 13/1000                                        \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 14/1000                                        \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 15/1000                                        \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 16/1000                                        \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 17/1000                                        \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 18/1000                                        \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 19/1000                                        \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 20/1000                                        \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 21/1000                                        \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 22/1000                                        \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 23/1000                                        \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 24/1000                                        \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 25/1000                                        \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 26/1000                                        \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 27/1000                                        \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 28/1000                                        \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 29/1000                                        \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 30/1000                                        \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 31/1000                                        \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 32/1000                                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 33/1000                                        \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 34/1000                                        \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 35/1000                                        \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 36/1000                                        \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 37/1000                                        \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 38/1000                                        \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 39/1000                                        \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 40/1000                                        \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 41/1000                                        \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 42/1000                                        \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 43/1000                                        \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 44/1000                                        \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 45/1000                                        \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 46/1000                                        \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 47/1000                                        \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 48/1000                                        \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 49/1000                                        \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 50/1000                                        \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 51/1000                                        \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 52/1000                                        \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 53/1000                                        \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 54/1000                                        \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 55/1000                                        \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 56/1000                                        \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 57/1000                                        \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 58/1000                                        \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 59/1000                                        \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 60/1000                                        \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 61/1000                                        \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 62/1000                                        \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 63/1000                                        \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 64/1000                                        \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 65/1000                                        \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 66/1000                                        \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 67/1000                                        \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 68/1000                                        \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 69/1000                                        \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 70/1000                                        \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 71/1000                                        \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 72/1000                                        \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 73/1000                                        \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 74/1000                                        \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 75/1000                                        \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 76/1000                                        \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 77/1000                                        \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 78/1000                                        \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 79/1000                                        \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 80/1000                                        \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 81/1000                                        \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 82/1000                                        \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 83/1000                                        \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/1000                                        \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 85/1000                                        \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 86/1000                                        \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 87/1000                                        \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 88/1000                                        \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 89/1000                                        \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 90/1000                                        \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 91/1000                                        \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 92/1000                                        \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 93/1000                                        \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 94/1000                                        \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 95/1000                                        \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 96/1000                                        \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 97/1000                                        \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 98/1000                                        \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 99/1000                                        \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 100/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 101/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 102/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 103/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 104/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 105/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 106/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 107/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 108/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 109/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 110/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 111/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 112/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 113/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 114/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 115/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 116/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 117/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 118/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 119/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 120/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 121/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 122/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 123/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 124/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 125/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 126/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 127/1000                                       \n",
      " - 2s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 128/1000                                       \n",
      " - 2s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 129/1000                                       \n",
      " - 2s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 130/1000                                       \n",
      " - 2s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 131/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 132/1000                                       \n",
      " - 2s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 133/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 134/1000                                       \n",
      " - 2s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 135/1000                                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 136/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 137/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 138/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 139/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 140/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 141/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 142/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 143/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 144/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 145/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 146/1000                                       \n",
      " - 2s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 147/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 148/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 149/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 150/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 151/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 152/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 153/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 154/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 155/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 156/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 157/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 158/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 159/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 160/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 161/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 162/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 163/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 164/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 165/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 166/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 167/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 168/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 169/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 170/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 171/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 172/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 173/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 174/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 175/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 176/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 177/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 178/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 179/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 180/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 181/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 182/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 183/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 184/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 185/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 186/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 187/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 188/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 189/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 190/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 191/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 192/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 193/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 194/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 195/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 196/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 197/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 198/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 199/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 200/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 201/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 202/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 203/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 204/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 205/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 206/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 207/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 208/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 209/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 210/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 211/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 212/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 213/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 214/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 215/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 216/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 217/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 218/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 219/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 220/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 221/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 222/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 223/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 224/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 225/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 226/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 227/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 228/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 229/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 230/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 231/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 232/1000                                       \n",
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 233/1000                                       \n",
      " - 2s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 234/1000                                       \n",
      " - 2s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 235/1000                                       \n",
      " - 2s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 236/1000                                       \n",
      " - 2s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 237/1000                                       \n",
      " - 2s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 238/1000                                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 239/1000                                       \n",
      " - 2s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 240/1000                                       \n",
      " - 2s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 241/1000                                       \n",
      " - 2s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 242/1000                                       \n",
      " - 2s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 243/1000                                       \n",
      " - 2s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 244/1000                                       \n",
      " - 2s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 245/1000                                       \n",
      " - 2s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 246/1000                                       \n",
      " - 4s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 247/1000                                       \n",
      " - 5s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 248/1000                                       \n",
      " - 5s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 249/1000                                       \n",
      " - 3s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 250/1000                                       \n",
      " - 3s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 251/1000                                       \n",
      " - 5s - loss: 0.4591 - mean_absolute_error: 0.6716 - val_loss: 0.4600 - val_mean_absolute_error: 0.6725\n",
      "\n",
      "Epoch 252/1000                                       \n",
      "  0%|          | 0/5 [03:52<?, ?trial/s, best loss=?]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-79-a7a17568735b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m                                       \u001b[0mmax_evals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                                       \u001b[0mtrials\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrials\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m                                       notebook_name='Ora')\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\hyperas\\optim.py\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(model, data, algo, max_evals, trials, functions, rseed, notebook_name, verbose, eval_space, return_space, keep_temp)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\hyperas\\optim.py\u001b[0m in \u001b[0;36mbase_minimizer\u001b[1;34m(model, data, functions, algo, max_evals, trials, rseed, full_model_string, notebook_name, verbose, stack, keep_temp)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar)\u001b[0m\n\u001b[0;32m    480\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m             \u001b[0mreturn_argmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_argmin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m             \u001b[0mshow_progressbar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshow_progressbar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m         )\n\u001b[0;32m    484\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\hyperopt\\base.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar)\u001b[0m\n\u001b[0;32m    684\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    685\u001b[0m             \u001b[0mreturn_argmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_argmin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 686\u001b[1;33m             \u001b[0mshow_progressbar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshow_progressbar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    687\u001b[0m         )\n\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar)\u001b[0m\n\u001b[0;32m    507\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    508\u001b[0m     \u001b[1;31m# next line is where the fmin is actually executed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 509\u001b[1;33m     \u001b[0mrval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    510\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    511\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    328\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 330\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    331\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, N, block_until_done)\u001b[0m\n\u001b[0;32m    284\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m                     \u001b[1;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 286\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    287\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[1;34m(self, N)\u001b[0m\n\u001b[0;32m    163\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 165\u001b[1;33m                     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    166\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"job exception: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\hyperopt\\base.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[0;32m    892\u001b[0m                 \u001b[0mprint_node_on_error\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrec_eval_print_node_on_error\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m             )\n\u001b[1;32m--> 894\u001b[1;33m             \u001b[0mrval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    895\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    896\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\DsLab\\Script Python\\temp_model.py\u001b[0m in \u001b[0;36mkeras_fmin_fnct\u001b[1;34m(space)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    878\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m           validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, mode, validation_in_fit, **kwargs)\u001b[0m\n\u001b[0;32m    362\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    363\u001b[0m           \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 364\u001b[1;33m           validation_in_fit=True)\n\u001b[0m\u001b[0;32m    365\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_results\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m         \u001b[0mval_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mval_results\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, mode, validation_in_fit, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m         \u001b[1;31m# Get outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 329\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    330\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3048\u001b[0m                                   np.expand_dims(sparse_coo.col, 1)), 1)\n\u001b[0;32m   3049\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse_coo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse_coo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3050\u001b[1;33m       \u001b[1;32mif\u001b[0m \u001b[0mtensor_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3051\u001b[0m         \u001b[1;31m# Case: feeding symbolic tensor.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3052\u001b[0m         \u001b[0mfeed_symbols\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py\u001b[0m in \u001b[0;36mis_tensor\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    985\u001b[0m     \u001b[0;31m`\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mif\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mx\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    986\u001b[0m   \"\"\"\n\u001b[1;32m--> 987\u001b[1;33m   return (isinstance(x, ops._TensorLike) or ops.is_dense_tensor_like(x) or  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    988\u001b[0m           (hasattr(x, \"is_tensor_like\") and x.is_tensor_like))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_run, best_model = optim.minimize(model=create_model,\n",
    "                                      data=data,\n",
    "                                      algo=tpe.suggest,\n",
    "                                      max_evals=5,\n",
    "                                      trials=Trials(),\n",
    "                                      notebook_name='Ora')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best performing model chosen hyper-parameters:\n",
      "{'Activation': 0, 'Dense': 4, 'Dropout': 0.8444244099007299, 'Dropout_1': 0.5350807190884803, 'batch_size': 5, 'optimizer': 1}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best performing model chosen hyper-parameters:\")\n",
    "print(best_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python37364bitbaseconda44edad810ccb401d8f06f6ce310604dc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
